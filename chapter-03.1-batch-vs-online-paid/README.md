# Lab 3.1 PAID Version â€“ Production-Grade Batch Inference
## Enterprise Batch Inference with OpenTelemetry & Cost Insights

---

## ğŸ¯ What You Will Learn

### Core Concepts

By completing this lab, you will master:

1. **Production Batch Inference Patterns** - How enterprise ML systems run batch workloads:
   - Full observability stack integration
   - Cost tracking and optimization
   - Resource constraint management
   - Performance monitoring at scale

2. **OpenTelemetry for Batch Workloads** - Industry-standard observability:
   - Distributed tracing for batch jobs
   - Metrics collection (records processed, latency, costs)
   - Integration with OpenTelemetry Collector
   - Exporting telemetry for analysis

3. **Cost Modeling for Batch AI** - Financial intelligence built-in:
   - Per-record cost calculation
   - Batch-level cost estimation
   - CPU utilization cost attribution
   - Cost optimization strategies

4. **Resource Management** - Production-grade controls:
   - CPU throttling configuration
   - Memory constraints
   - Execution time limits
   - Cost vs. speed tradeoffs

### Practical Skills

You will be able to:

- âœ… Build enterprise-grade batch inference pipelines
- âœ… Implement OpenTelemetry in batch workloads
- âœ… Track and optimize batch processing costs
- âœ… Monitor record-level and batch-level performance
- âœ… Configure resource constraints for cost control
- âœ… Deploy production-ready CronJobs with observability
- âœ… Export telemetry to observability backends
- âœ… Debug batch job performance issues

### Real-World Applications

**ML Platform Engineers** will learn:
- How to standardize observability across batch ML pipelines
- Cost attribution for ML workloads
- Production deployment patterns for batch inference

**FinOps Teams** will learn:
- How to track ML inference costs per record
- Resource optimization for batch workloads
- Cost modeling for capacity planning

**SREs** will learn:
- How to monitor batch job health
- Setting up alerts for batch failures
- Performance troubleshooting with traces

**Data Engineers** will learn:
- Integrating observability into data pipelines
- Batch processing performance optimization
- Cost-aware pipeline design

---

## ğŸ“‹ Prerequisites

### Required Software
- **Operating System:** Ubuntu 22.04 (or similar Linux / WSL2 / macOS)
- **Docker:** Version 24 or higher
- **kind:** Kubernetes in Docker
- **kubectl:** Version 1.29 or higher
- **Python:** Version 3.11 or higher
- **Git:** For cloning repositories

### Required Knowledge
- Completion of Lab 3.1 FREE version (or equivalent batch job knowledge)
- Basic understanding of OpenTelemetry concepts
- Familiarity with Kubernetes Jobs and CronJobs
- Understanding of resource requests and limits

### Recommended Reading
- OpenTelemetry for batch processing
- Kubernetes resource management
- Cloud cost optimization for ML workloads

---

## ğŸ—ï¸ Architecture Overview

### What You're Building

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Kubernetes Cluster                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Namespace: ai-ml-lab-3-1-paid                     â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚
â”‚  â”‚  â”‚  Batch Inference Job                             â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  Pod: batch-inference-paid-xxxxx         â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚                                           â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  1. Initialize OpenTelemetry SDK         â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  2. Read input.jsonl                     â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  3. For each record:                     â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚     â”œâ”€ Create trace span                 â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚     â”œâ”€ Compute prediction                â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚     â”œâ”€ Track latency                     â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚     â”œâ”€ Calculate cost                    â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚     â””â”€ Export metrics                    â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  4. Generate batch summary               â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  5. Export telemetry to collector        â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  6. Exit (Status: Completed)             â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚                                           â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  Resource Limits:                        â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - CPU: 500m (throttled for cost)       â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Memory: 512Mi                         â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚                       â”‚                          â”‚    â”‚  â”‚
â”‚  â”‚  â”‚                       â”‚ OTLP                     â”‚    â”‚  â”‚
â”‚  â”‚  â”‚                       â–¼                          â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  OpenTelemetry Collector                 â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚                                           â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  Receivers:                               â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - OTLP (gRPC: 4317, HTTP: 4318)        â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚                                           â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  Processors:                              â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Batch (optimize exports)              â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Memory limiter                        â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚                                           â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  Exporters:                               â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Logging (stdout)                      â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - [Future: Prometheus, Jaeger, etc.]   â”‚   â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚
â”‚  â”‚  â”‚  CronJob (Scheduled Batch Processing)            â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  Schedule: "*/10 * * * *" (every 10 minutes)    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  Creates Jobs â†’ Same flow as above               â”‚    â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Observability Data Flow

```
Batch Job
    â†“
[Trace Spans] â†’ Per-record processing spans with timing
[Metrics]     â†’ Records processed, latency histogram, cost
[Logs]        â†’ Structured logs with trace IDs
    â†“
OTLP Protocol (gRPC/HTTP)
    â†“
OpenTelemetry Collector
    â†“
Processors (Batch, Filter, Enrich)
    â†“
Exporters
    â”œâ”€ Stdout (for this lab)
    â”œâ”€ Prometheus (production)
    â”œâ”€ Jaeger (production)
    â””â”€ Cloud providers (production)
```

---

## ğŸ†š FREE vs PAID Comparison

| Feature | FREE Version | PAID Version |
|---------|-------------|--------------|
| **Batch Inference** | âœ… Basic | âœ… Production-grade |
| **Kubernetes Jobs** | âœ… Simple | âœ… With resource limits |
| **CronJobs** | âœ… Basic schedule | âœ… With retry policies |
| **Logging** | âœ… Stdout only | âœ… Structured + trace IDs |
| **OpenTelemetry Traces** | âŒ | âœ… Per-record spans |
| **OpenTelemetry Metrics** | âŒ | âœ… Comprehensive metrics |
| **Cost Modeling** | âŒ | âœ… Per-record cost tracking |
| **CPU Throttling** | âŒ | âœ… Configurable limits |
| **OTel Collector** | âŒ | âœ… Included & configured |
| **Resource Management** | âŒ Basic | âœ… Requests & limits |
| **Observability Export** | âŒ | âœ… To collector |
| **Production Ready** | Learning only | âœ… Yes |

---

## ğŸ“ Repository Structure

```
lab-03.1-batch-vs-online-paid/
â”œâ”€â”€ README.md                       â† This file
â”œâ”€â”€ setup.md                        â† Detailed setup guide
â”œâ”€â”€ kind-mcp-cluster.yaml           â† Cluster configuration
â”œâ”€â”€ Dockerfile                      â† Container image definition
â”œâ”€â”€ .env.example                    â† Environment configuration
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ batch_job.py                â† Batch inference with OTel
â”‚   â”œâ”€â”€ config.py                   â† Configuration management
â”‚   â”œâ”€â”€ cost_model.py               â† Cost calculation logic
â”‚   â”œâ”€â”€ requirements.txt            â† Python dependencies
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ input.jsonl             â† Sample dataset
â”‚   â””â”€â”€ tests/
â”‚       â””â”€â”€ test_batch_job.py       â† Unit tests
â””â”€â”€ k8s/
    â”œâ”€â”€ namespace.yaml              â† Namespace isolation
    â”œâ”€â”€ otel-collector-config.yaml  â† Collector ConfigMap
    â”œâ”€â”€ otel-collector-deploy.yaml  â† Collector deployment
    â”œâ”€â”€ job-batch-once.yaml         â† One-time batch job
    â””â”€â”€ cronjob-batch.yaml          â† Scheduled batch job
```

---

## ğŸš€ Quick Start Guide

### Step 1: Navigate to Lab Directory

```bash
cd lab-03.1-batch-vs-online-paid
```

### Step 2: Configure Environment

```bash
cp .env.example .env
```

Review configuration:
```bash
cat .env
```

**Key settings:**
```bash
# OpenTelemetry
OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector-paid:4317
OTEL_SERVICE_NAME=batch-inference-service

# Cost modeling
COST_PER_CPU_HOUR=0.04        # $0.04 per CPU-hour
COST_PER_MEMORY_GB_HOUR=0.005 # $0.005 per GB-hour

# Resource throttling
CPU_LIMIT=500m                 # Throttle to 0.5 CPU
MEMORY_LIMIT=512Mi
```

### Step 3: Create kind Cluster

```bash
kind create cluster --config kind-mcp-cluster.yaml
kubectl get nodes
```

### Step 4: Build Docker Image

```bash
docker build -t ai-lab-3-1-paid:v1 .
```

### Step 5: Load Image into kind

```bash
kind load docker-image ai-lab-3-1-paid:v1 --name mcp-cluster
```

### Step 6: Deploy All Resources

```bash
# Create namespace
kubectl apply -f k8s/namespace.yaml

# Deploy OpenTelemetry Collector
kubectl apply -f k8s/otel-collector-config.yaml
kubectl apply -f k8s/otel-collector-deploy.yaml

# Deploy batch jobs
kubectl apply -f k8s/job-batch-once.yaml
kubectl apply -f k8s/cronjob-batch.yaml
```

### Step 7: Verify Deployment

```bash
kubectl get all -n ai-ml-lab-3-1-paid
```

### Step 8: View Batch Job Output

```bash
kubectl logs -n ai-ml-lab-3-1-paid -l app=batch-inference-paid
```

**Expected Output:**
```json
{"level": "INFO", "message": "Starting batch inference job", "trace_id": "abc123..."}
{"id": 1, "prediction": 6.0, "latency_ms": 45, "cost_usd": 0.0001, "trace_id": "def456..."}
{"id": 2, "prediction": 15.0, "latency_ms": 48, "cost_usd": 0.0001, "trace_id": "ghi789..."}
{"summary": {
  "total_records": 2,
  "avg_prediction": 10.5,
  "total_latency_ms": 93,
  "avg_latency_ms": 46.5,
  "total_cost_usd": 0.0002,
  "cost_per_record_usd": 0.0001
}}
```

### Step 9: View OpenTelemetry Collector Logs

```bash
kubectl logs -n ai-ml-lab-3-1-paid deploy/otel-collector-paid
```

**Expected Output:**
```
2024-01-15T10:30:00.123Z info    TracesExporter  {"traces": 2}
2024-01-15T10:30:01.234Z info    MetricsExporter {"metrics": 6}

Trace details:
  Service: batch-inference-service
  Span: process_record
  Duration: 45ms
  Attributes:
    record_id: 1
    prediction: 6.0
    cost_usd: 0.0001

Metrics:
  batch_total_records: 2
  batch_processing_ms: 93
  record_latency_ms (histogram):
    - Bucket[0-50ms]: 2
    - Bucket[50-100ms]: 0
  batch_cost_usd: 0.0002
```

---

## ğŸ“Š Understanding Production Features

### OpenTelemetry Integration

**1. Trace Spans:**
Every record gets its own span:
```python
with tracer.start_as_current_span("process_record") as span:
    span.set_attribute("record.id", record_id)
    span.set_attribute("prediction", prediction)
    span.set_attribute("cost_usd", cost)
```

**2. Metrics Exported:**
- `batch_total_records` (Counter) - Total records processed
- `record_latency_ms` (Histogram) - Per-record latency distribution
- `batch_processing_ms` (Gauge) - Total batch processing time
- `batch_cost_usd` (Gauge) - Total batch cost
- `cost_per_record_usd` (Gauge) - Average cost per record

**3. Structured Logs:**
All logs include trace IDs for correlation:
```json
{
  "level": "INFO",
  "message": "Record processed",
  "record_id": 1,
  "trace_id": "abc123...",
  "span_id": "def456..."
}
```

### Cost Modeling

**Per-Record Cost Calculation:**
```python
# CPU cost
cpu_time_seconds = record_latency_ms / 1000
cpu_cost = (cpu_limit_cores * COST_PER_CPU_HOUR * cpu_time_seconds) / 3600

# Memory cost
memory_gb = memory_limit_bytes / (1024**3)
memory_cost = (memory_gb * COST_PER_MEMORY_GB_HOUR * cpu_time_seconds) / 3600

# Total cost per record
total_cost = cpu_cost + memory_cost
```

**Cost Tracking:**
- Real-time cost calculation per record
- Batch-level cost aggregation
- Cost exported as metrics
- Cost optimization recommendations

### Resource Management

**CPU Throttling:**
```yaml
resources:
  requests:
    cpu: "250m"      # Guaranteed minimum
    memory: "256Mi"
  limits:
    cpu: "500m"      # Throttled maximum (cost control)
    memory: "512Mi"   # OOM protection
```

**Why Throttle?**
- **Cost Control:** Lower CPU = lower cost
- **Predictability:** Consistent execution time
- **Fairness:** Share cluster resources
- **Optimization:** Force efficient code

---

## ğŸ§ª Running Unit Tests

From the `app/` directory:

```bash
cd app
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
pytest -v
```

**Expected Output:**
```
================== test session starts ==================
collected 3 items

tests/test_batch_job.py::test_batch_inference PASSED     [33%]
tests/test_batch_job.py::test_cost_calculation PASSED    [66%]
tests/test_batch_job.py::test_telemetry_export PASSED    [100%]

=================== 3 passed in 0.15s ===================
```

---

## ğŸ’° Cost Analysis

### Running in KIND: $0/month

This lab runs locally with zero cloud costs.

### Cloud Deployment Cost Modeling

**Scenario:** CronJob runs every hour (24 times/day)

**Job Specifications:**
- Runtime: 2 minutes per execution
- CPU: 0.5 cores (throttled)
- Memory: 512Mi
- Records processed: 1,000 per run

**Monthly Calculation:**
```
Executions per month: 24/day Ã— 30 days = 720 jobs
Total runtime: 720 Ã— 2 min = 1,440 min = 24 hours

Compute cost:
  CPU: 0.5 cores Ã— 24 hours Ã— $0.04/core-hour = $0.48
  Memory: 0.5 GB Ã— 24 hours Ã— $0.005/GB-hour = $0.06
  Total compute: $0.54

Storage (logs, minimal): $0.10
Collector overhead: $0.20

Total: ~$0.84/month
```

**Per-Record Cost:**
```
Total records/month: 720 jobs Ã— 1,000 records = 720,000 records
Cost per record: $0.84 / 720,000 = $0.0000012 per record
Cost per 1M records: $1.20
```

### Cost Optimization Strategies

**1. Adjust CPU Throttling:**
```yaml
# Slower but cheaper
cpu: "250m"  # Cost: ~$0.27/month (50% savings)

# Faster but more expensive
cpu: "1000m" # Cost: ~$0.96/month (80% increase)
```

**2. Optimize Schedule:**
```yaml
# Every hour (expensive)
schedule: "0 * * * *"  # 720 jobs/month

# Every 6 hours (75% savings)
schedule: "0 */6 * * *"  # 120 jobs/month

# Daily at 2 AM (97% savings)
schedule: "0 2 * * *"  # 30 jobs/month
```

**3. Batch More Records:**
```
1,000 records/job â†’ $0.0000012 per record
10,000 records/job â†’ $0.00000012 per record (90% savings!)
```

**4. Use Spot Instances:**
```
Regular: $0.84/month
Spot/Preemptible: $0.17/month (80% savings)
```

---

## ğŸ“ Key Learning Outcomes

### Conceptual Understanding

After completing this lab, you understand:

âœ… **Enterprise Batch Observability:**
- How to instrument batch jobs with OpenTelemetry
- Difference between API and batch observability patterns
- Importance of per-record vs batch-level metrics

âœ… **Cost Attribution for ML:**
- How to calculate per-record inference costs
- Impact of resource limits on costs
- Cost optimization strategies for batch workloads

âœ… **Production Deployment Patterns:**
- Resource management for batch jobs
- Observability collector architecture
- Telemetry export and aggregation

âœ… **Performance vs Cost Tradeoffs:**
- How CPU throttling affects cost and speed
- When to optimize for cost vs latency
- Right-sizing batch workloads

### Technical Skills

You can now:

âœ… **Implement OpenTelemetry in batch jobs**
âœ… **Calculate and track inference costs**
âœ… **Configure resource constraints for cost control**
âœ… **Export telemetry to collectors**
âœ… **Monitor batch job performance**
âœ… **Debug batch issues using traces**
âœ… **Optimize batch workloads for cost**

### Production Patterns

You've learned:

âœ… **Cost-aware engineering** - Building with cost as a first-class concern
âœ… **Observability-driven development** - Using telemetry to optimize
âœ… **Resource management** - Balancing cost, speed, and reliability
âœ… **Enterprise monitoring** - Full-stack observability for batch jobs

---

## ğŸ”§ Troubleshooting

### Issue: Collector Not Receiving Data

**Check collector status:**
```bash
kubectl logs -n ai-ml-lab-3-1-paid deploy/otel-collector-paid
```

**Test connectivity:**
```bash
kubectl exec -n ai-ml-lab-3-1-paid -l app=batch-inference-paid -- nc -zv otel-collector-paid 4317
```

**Verify configuration:**
```bash
kubectl get configmap -n ai-ml-lab-3-1-paid otel-collector-config -o yaml
```

### Issue: Cost Calculations Seem Wrong

**Check environment variables:**
```bash
kubectl describe pod -n ai-ml-lab-3-1-paid -l app=batch-inference-paid | grep -A10 "Environment"
```

**Verify cost parameters:**
- `COST_PER_CPU_HOUR` - Should match cloud pricing
- `COST_PER_MEMORY_GB_HOUR` - Should match cloud pricing
- `CPU_LIMIT` - Should match resource limits

### Issue: Job Runs Slower Than Expected

**Check if CPU throttled:**
```bash
kubectl top pod -n ai-ml-lab-3-1-paid
```

**Review resource limits:**
```bash
kubectl describe pod -n ai-ml-lab-3-1-paid -l app=batch-inference-paid | grep -A5 "Limits"
```

**Consider increasing CPU limit:**
```yaml
limits:
  cpu: "1000m"  # Double the CPU
```

---

## ğŸ§¹ Cleanup

### Remove All Resources

```bash
kubectl delete namespace ai-ml-lab-3-1-paid
```

### Delete kind Cluster

```bash
kind delete cluster --name mcp-cluster
```

---

## ğŸ“š Next Steps

### Production Enhancements

**1. Export to Real Backends:**
```yaml
exporters:
  prometheus:
    endpoint: "prometheus:9090"
  jaeger:
    endpoint: "jaeger:14250"
  otlp/datadog:
    endpoint: "https://api.datadoghq.com"
```

**2. Add Cost Alerting:**
- Alert when cost per record exceeds threshold
- Daily/weekly cost reports
- Budget tracking and forecasting

**3. Implement Dynamic Scaling:**
- Adjust CPU based on workload size
- Scale horizontally for large batches
- Auto-tune resource limits

**4. Add Persistent Storage:**
- Save predictions to S3/GCS
- Database integration
- Data versioning

---

## ğŸ‰ Congratulations!

You've completed Lab 3.1 PAID Version!

### What You've Mastered:

âœ… **Production Batch Observability** - Enterprise-grade monitoring  
âœ… **Cost-Aware ML Engineering** - Financial intelligence in code  
âœ… **OpenTelemetry Integration** - Industry-standard telemetry  
âœ… **Resource Optimization** - Cost vs performance tradeoffs  
âœ… **Enterprise Patterns** - Real-world production deployments  

### Real-World Impact:

These skills are used by:
- **Major tech companies** for cost optimization
- **FinOps teams** for ML cost attribution
- **Platform teams** for standardized observability
- **ML engineers** for performance optimization

You now have production-grade batch ML skills!

Happy learning! ğŸš€ğŸ’°ğŸ“Š