# Lab 4.1 PAID Version â€“ Production Infrastructure Investigation Agent
## Enterprise Agent with Tools, Memory Layers, and LLM Planning

---

## ğŸ¯ What You Will Learn

### Core Concepts

By completing this lab, you will master:

1. **Production Agent Architecture** - Enterprise-grade autonomous systems:
   - **Multi-layer memory** (working + episodic)
   - **Tool registry with metadata** (permissions, timeouts, rate limits)
   - **Safe execution sandbox** (isolation, error handling)
   - **LLM-based planning** (with deterministic fallback)
   - **Plan execution engine** (step tracking, rollback)

2. **Advanced Memory Systems** - Real-world context management:
   - **Working Memory**: Short-term context (simulated Redis)
   - **Episodic Memory**: Long-term investigation history (SQLite/Postgres)
   - **Memory integration**: How agents use past experience
   - **Pattern detection**: Learning from historical data

3. **Tool Management Patterns** - Enterprise tool orchestration:
   - **Tool Registry**: Centralized capability management
   - **Metadata-driven execution**: Permissions, timeouts, retries
   - **Safe Executor**: Sandboxed tool execution
   - **Tool versioning**: Managing tool evolution

4. **LLM Integration** - Bringing intelligence to agents:
   - **LLM client abstraction**: Provider-agnostic design
   - **Prompt engineering**: Effective LLM communication
   - **Fallback strategies**: Graceful degradation without LLM
   - **Cost-aware usage**: Optimizing LLM calls

### Practical Skills

You will be able to:

- âœ… Build production-grade AI agents with full architecture
- âœ… Implement multi-layer memory systems
- âœ… Design tool registries with rich metadata
- âœ… Create safe execution sandboxes
- âœ… Integrate LLMs for planning (optional)
- âœ… Implement deterministic fallback planning
- âœ… Deploy agents with persistence layers
- âœ… Test complex agent behavior
- âœ… Debug multi-component agent systems

### Real-World Applications

**SRE Teams** will learn:
- Building autonomous incident response systems
- Production-grade tool orchestration
- Historical investigation analysis
- Learning from past incidents

**Platform Engineers** will learn:
- Enterprise agent architecture
- Tool governance and safety
- Memory layer integration
- Agent deployment patterns

**ML Engineers** will learn:
- LLM integration in production systems
- Agent memory architectures
- Tool execution frameworks
- Production agent observability

---

## ğŸ“‹ Prerequisites

### Required Software
- **Operating System:** Ubuntu 22.04 (or similar Linux / WSL2 / macOS)
- **Docker:** Version 24 or higher
- **kind:** Kubernetes in Docker
- **kubectl:** Version 1.29 or higher
- **Python:** Version 3.11 or higher
- **curl:** For API testing

### Optional (for LLM Features)
- **OpenAI API Key:** For real LLM-based planning
- **openai Python package:** For OpenAI integration

### Required Knowledge
- Completion of Lab 4.1 FREE version (strongly recommended)
- Understanding of memory systems (cache, database)
- Basic knowledge of LLMs and prompting
- Advanced Kubernetes concepts

### Verification Commands

```bash
# Check required tools
docker version
kind version
kubectl version --client
python3 --version

# Optional: Check OpenAI key (if using LLM)
echo $OPENAI_API_KEY
```

---

## ğŸ—ï¸ Architecture Overview

### What You're Building

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Kubernetes Cluster                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Namespace: ai-ml-lab-4-1-paid                     â”‚  â”‚
â”‚  â”‚                                                            â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚
â”‚  â”‚  â”‚  Pod: paid-agent-lab-4-1-*                       â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  FastAPI Controller (Port 8000)            â”‚  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Receives alerts                         â”‚  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Routes to agent                         â”‚  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚                   â”‚                               â”‚    â”‚  â”‚
â”‚  â”‚  â”‚                   â–¼                               â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  InfrastructureAgent (Core)                â”‚  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚                                            â”‚  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  1. Receive alert                          â”‚  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  2. Consult memory for context            â”‚  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  3. Generate plan (LLM or fallback)       â”‚  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  4. Execute plan with tools               â”‚  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  5. Store results in memory               â”‚  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  6. Return comprehensive report           â”‚  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚                  â”‚                                â”‚    â”‚  â”‚
â”‚  â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚    â”‚  â”‚
â”‚  â”‚  â”‚    â”‚                           â”‚                â”‚    â”‚  â”‚
â”‚  â”‚  â”‚    â–¼                           â–¼                â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  LLMClient   â”‚      â”‚  MemoryManager   â”‚    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚              â”‚      â”‚                  â”‚    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ - OpenAI API â”‚      â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ - Claude API â”‚      â”‚ â”‚ Working      â”‚ â”‚    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ - Fallback   â”‚      â”‚ â”‚ Memory       â”‚ â”‚    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚   Planner    â”‚      â”‚ â”‚ (Redis-like) â”‚ â”‚    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚                        â”‚                  â”‚    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚                        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚ â”‚ Episodic     â”‚ â”‚    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ Tool         â”‚      â”‚ â”‚ Memory       â”‚ â”‚    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ Registry     â”‚      â”‚ â”‚ (SQLite/PG)  â”‚ â”‚    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚              â”‚      â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ Tools:       â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ - check_pods â”‚                              â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ - get_logs   â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ - get_metricsâ”‚      â”‚ PlanExecution    â”‚    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ - restart_podâ”‚      â”‚ Engine           â”‚    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚              â”‚      â”‚                  â”‚    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ Metadata:    â”‚      â”‚ - Step tracking  â”‚    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ - Permissionsâ”‚      â”‚ - Error handling â”‚    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ - Timeouts   â”‚      â”‚ - Rollback       â”‚    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚ - Rate limitsâ”‚      â”‚ - Retries        â”‚    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚  â”‚
â”‚  â”‚  â”‚         â”‚                                       â”‚    â”‚  â”‚
â”‚  â”‚  â”‚         â–¼                                       â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  SafeExecutor (Sandbox)                  â”‚  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Isolation                             â”‚  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Timeout enforcement                   â”‚  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Permission checking                   â”‚  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  - Error recovery                        â”‚  â”‚    â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Advanced Agent Workflow

```
1. Alert Received
   â†“
2. Check Working Memory
   "Have we seen this before recently?"
   â†“
3. Query Episodic Memory
   "What have we learned about this service?"
   â†“
4. Generate Plan (LLM or Fallback)
   LLM: "Based on context, here's what to investigate..."
   Fallback: Deterministic rules-based plan
   â†“
5. Execute Plan with SafeExecutor
   For each step:
     - Verify permissions
     - Set timeout
     - Execute in sandbox
     - Handle errors
     - Track progress
   â†“
6. Aggregate Results
   Collect outputs from all steps
   â†“
7. Store in Both Memory Layers
   Working: Recent context (expires)
   Episodic: Permanent record (searchable)
   â†“
8. Return Comprehensive Report
   {
     "alert": {...},
     "plan": {...},
     "steps": [...],
     "episodic_id": "UUID",
     "memory_snapshot": {...},
     "learned_patterns": [...]
   }
```

---

## ğŸ†š FREE vs PAID Comparison

| Feature | FREE Version | PAID Version |
|---------|-------------|--------------|
| **Memory System** | In-process only | Multi-layer (Working + Episodic) |
| **Working Memory** | âŒ | âœ… Redis-like (in-process) |
| **Episodic Memory** | âŒ | âœ… SQLite (simulates Postgres) |
| **Tool Registry** | Basic list | Rich metadata + permissions |
| **Tool Metadata** | âŒ | âœ… Timeouts, retries, permissions |
| **Safe Executor** | Basic error handling | Full sandbox + isolation |
| **Planning** | Simple rules | LLM-based + fallback |
| **LLM Integration** | âŒ | âœ… OpenAI/Claude with abstraction |
| **Plan Execution** | Sequential only | Engine with tracking |
| **Step Tracking** | âŒ | âœ… Per-step status |
| **Error Recovery** | Basic | Advanced with rollback |
| **Historical Learning** | âŒ | âœ… Pattern detection |
| **Production Ready** | Learning only | âœ… Yes |

---

## ğŸ“ Repository Structure

```
lab-04.1-first-ai-agent-paid/
â”œâ”€â”€ README.md                   â† This file
â”œâ”€â”€ setup.md                    â† Detailed setup guide
â”œâ”€â”€ kind-mcp-cluster.yaml       â† Cluster configuration
â”œâ”€â”€ Dockerfile                  â† Container image definition
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 â† FastAPI controller
â”‚   â”œâ”€â”€ agent.py                â† InfrastructureAgent orchestrator
â”‚   â”œâ”€â”€ tools.py                â† Tool Registry with metadata
â”‚   â”œâ”€â”€ memory.py               â† Working + Episodic Memory
â”‚   â”œâ”€â”€ executor.py             â† Safe tool sandbox
â”‚   â”œâ”€â”€ planning.py             â† PlanExecutionEngine
â”‚   â”œâ”€â”€ llm_client.py           â† LLM abstraction (with fallback)
â”‚   â”œâ”€â”€ config.py               â† Settings (env-driven)
â”‚   â”œâ”€â”€ models.py               â† Pydantic models
â”‚   â”œâ”€â”€ requirements.txt        â† Python dependencies
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ test_main.py        â† API tests
â”‚       â”œâ”€â”€ test_agent.py       â† Agent orchestration tests
â”‚       â”œâ”€â”€ test_tools.py       â† Tool execution tests
â”‚       â”œâ”€â”€ test_memory.py      â† Memory system tests
â”‚       â””â”€â”€ test_planning.py    â† Planning engine tests
â””â”€â”€ k8s/
    â”œâ”€â”€ namespace.yaml          â† Namespace isolation
    â”œâ”€â”€ deployment.yaml         â† Agent deployment
    â””â”€â”€ service.yaml            â† ClusterIP service
```

---

## ğŸš€ Quick Start Guide

### Option 1: Run Locally (Recommended First)

**Step 1: Navigate to app directory**
```bash
cd lab-04.1-first-ai-agent-paid/app
```

**Step 2: Create virtual environment**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

**Step 3: Install dependencies**
```bash
pip install -r requirements.txt
```

**Step 4: Run the agent**
```bash
uvicorn main:app --reload
```

**Step 5: Test with alert**

In another terminal:
```bash
curl -X POST http://localhost:8000/alerts \
  -H "Content-Type: application/json" \
  -d '{"type": "high_memory", "service": "web-app"}'
```

**Expected Response:**
```json
{
  "alert": {
    "type": "high_memory",
    "service": "web-app",
    "timestamp": "2024-01-15T10:30:00Z"
  },
  "plan": {
    "reasoning": "High memory alert requires checking pod status, metrics, and recent events",
    "steps": [
      {"tool": "check_pods", "reason": "Verify pod health"},
      {"tool": "get_metrics", "reason": "Analyze memory usage"},
      {"tool": "check_events", "reason": "Look for OOM events"}
    ]
  },
  "execution": {
    "steps": [
      {
        "step": 1,
        "tool": "check_pods",
        "status": "success",
        "result": "Found 5 pods: 4 healthy, 1 high memory (pod-456)",
        "duration_ms": 45
      },
      {
        "step": 2,
        "tool": "get_metrics",
        "status": "success",
        "result": "web-app metrics - CPU: 45%, Memory: 92%",
        "duration_ms": 32
      },
      {
        "step": 3,
        "tool": "check_events",
        "status": "success",
        "result": "Warning: OOMKilled pod-456 5 minutes ago",
        "duration_ms": 28
      }
    ],
    "total_duration_ms": 105
  },
  "episodic_id": "550e8400-e29b-41d4-a716-446655440000",
  "memory_snapshot": {
    "working_memory": {
      "current_alert": {"type": "high_memory", "service": "web-app"},
      "recent_tools_used": ["check_pods", "get_metrics", "check_events"]
    },
    "episodic_memory": {
      "total_investigations": 1,
      "similar_past_cases": 0,
      "learned_patterns": []
    }
  },
  "recommendations": [
    "Pod pod-456 is experiencing memory pressure",
    "Consider increasing memory limits or investigating memory leaks"
  ]
}
```

---

### Option 2: Run with LLM Planning (Optional)

**Step 1: Set OpenAI API key**
```bash
export OPENAI_API_KEY="sk-your-key-here"
```

**Step 2: Install OpenAI package**
```bash
pip install openai
```

**Step 3: Run the agent**
```bash
uvicorn main:app --reload
```

**Step 4: Test - LLM will generate the plan**
```bash
curl -X POST http://localhost:8000/alerts \
  -H "Content-Type: application/json" \
  -d '{"type": "high_cpu", "service": "payment-api"}'
```

**Expected: Plan reasoning will be more natural and detailed**

---

### Option 3: Run on Kubernetes

**Step 1: Create kind cluster**
```bash
cd lab-04.1-first-ai-agent-paid
kind create cluster --config kind-mcp-cluster.yaml
```

**Step 2: Build Docker image**
```bash
docker build -t paid-agent-lab-4-1:v1 .
```

**Step 3: Load into kind**
```bash
kind load docker-image paid-agent-lab-4-1:v1 --name mcp-cluster
```

**Step 4: Deploy**
```bash
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml
```

**Step 5: Port-forward and test**
```bash
kubectl port-forward -n ai-ml-lab-4-1-paid svc/paid-agent-lab-4-1 8000:8000

# In another terminal
curl -X POST http://localhost:8000/alerts \
  -H "Content-Type: application/json" \
  -d '{"type":"high_cpu","service":"payment-api"}'
```

---

## ğŸ“Š Understanding Production Components

### 1. Multi-Layer Memory System

**Working Memory (Short-term):**
```python
class WorkingMemory:
    """Simulates Redis - fast, temporary context"""
    
    def __init__(self):
        self.cache = {}  # In production: Redis
        self.ttl = 3600  # 1 hour expiration
    
    def set(self, key, value):
        self.cache[key] = {
            "value": value,
            "timestamp": time.time()
        }
    
    def get(self, key):
        if key in self.cache:
            if time.time() - self.cache[key]["timestamp"] < self.ttl:
                return self.cache[key]["value"]
        return None
```

**Episodic Memory (Long-term):**
```python
class EpisodicMemory:
    """Simulates Postgres - permanent, searchable history"""
    
    def __init__(self, db_path="episodic.db"):
        self.conn = sqlite3.connect(db_path)  # In production: Postgres
        self._create_tables()
    
    def store_investigation(self, alert, plan, results):
        investigation_id = str(uuid.uuid4())
        self.conn.execute("""
            INSERT INTO investigations 
            (id, timestamp, alert_type, service, plan, results)
            VALUES (?, ?, ?, ?, ?, ?)
        """, (investigation_id, datetime.now(), 
              alert["type"], alert["service"],
              json.dumps(plan), json.dumps(results)))
        return investigation_id
    
    def query_similar(self, alert_type, service):
        return self.conn.execute("""
            SELECT * FROM investigations
            WHERE alert_type = ? AND service = ?
            ORDER BY timestamp DESC LIMIT 5
        """, (alert_type, service)).fetchall()
```

### 2. Tool Registry with Metadata

```python
class ToolRegistry:
    def __init__(self):
        self.tools = {
            "check_pods": {
                "function": self.check_pods,
                "metadata": {
                    "permissions": ["read:pods"],
                    "timeout_seconds": 30,
                    "retry_count": 3,
                    "rate_limit": "100/minute",
                    "description": "Check pod status for a service"
                }
            },
            "restart_pod": {
                "function": self.restart_pod,
                "metadata": {
                    "permissions": ["write:pods"],
                    "timeout_seconds": 60,
                    "retry_count": 1,
                    "rate_limit": "10/minute",
                    "requires_approval": True
                }
            }
        }
```

**Why metadata matters:**
- **Permissions**: Control what tools can do
- **Timeouts**: Prevent hanging operations
- **Retries**: Handle transient failures
- **Rate limits**: Prevent overwhelming systems
- **Approval**: Require human confirmation for dangerous actions

### 3. Safe Executor Sandbox

```python
class SafeExecutor:
    def execute(self, tool_name, *args, **kwargs):
        tool_info = self.registry.get(tool_name)
        
        # 1. Check permissions
        if not self._has_permission(tool_info["metadata"]["permissions"]):
            return {"error": "Permission denied"}
        
        # 2. Check rate limits
        if not self._check_rate_limit(tool_name):
            return {"error": "Rate limit exceeded"}
        
        # 3. Execute with timeout
        try:
            with timeout(tool_info["metadata"]["timeout_seconds"]):
                result = tool_info["function"](*args, **kwargs)
            return {"success": True, "result": result}
        except TimeoutError:
            return {"error": "Tool execution timeout"}
        except Exception as e:
            # 4. Handle errors with retry
            if self._should_retry(e):
                return self._retry_execution(tool_name, *args, **kwargs)
            return {"error": str(e)}
```

### 4. LLM Client with Fallback

```python
class LLMClient:
    def generate_plan(self, alert, memory_context):
        # Try LLM first
        if self.api_key:
            try:
                plan = self._call_llm(alert, memory_context)
                return plan
            except Exception as e:
                logger.warning(f"LLM failed: {e}, using fallback")
        
        # Fallback to deterministic planner
        return self._fallback_planner(alert)
    
    def _call_llm(self, alert, memory_context):
        prompt = f"""
        You are an infrastructure investigation agent.
        
        Alert: {alert}
        Recent Context: {memory_context}
        
        Generate an investigation plan with these tools:
        - check_pods: Check pod status
        - get_logs: Retrieve recent logs
        - get_metrics: Get current metrics
        - check_events: Check Kubernetes events
        
        Provide reasoning and tool sequence.
        """
        
        response = openai.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        return self._parse_llm_response(response)
```

---

## ğŸ§ª Running Tests

### Local Testing

```bash
cd lab-04.1-first-ai-agent-paid/app
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
pytest -v
```

**Expected Output:**
```
================== test session starts ==================
collected 15 items

tests/test_tools.py::test_tool_registry PASSED         [6%]
tests/test_tools.py::test_tool_metadata PASSED         [13%]
tests/test_tools.py::test_tool_execution PASSED        [20%]
tests/test_memory.py::test_working_memory PASSED       [26%]
tests/test_memory.py::test_episodic_memory PASSED      [33%]
tests/test_memory.py::test_memory_integration PASSED   [40%]
tests/test_planning.py::test_plan_generation PASSED    [46%]
tests/test_planning.py::test_plan_execution PASSED     [53%]
tests/test_planning.py::test_error_handling PASSED     [60%]
tests/test_agent.py::test_agent_initialization PASSED  [66%]
tests/test_agent.py::test_agent_investigation PASSED   [73%]
tests/test_agent.py::test_memory_integration PASSED    [80%]
tests/test_main.py::test_health_endpoint PASSED        [86%]
tests/test_main.py::test_alerts_endpoint PASSED        [93%]
tests/test_main.py::test_memory_persistence PASSED     [100%]

=================== 15 passed in 2.35s ===================
```

**All tests work offline - no LLM or external databases required!**

---

## ğŸ’° Cost Analysis

### Running in KIND: $0/month

Completely free for development and learning.

### Cloud Deployment: $10-15/month

**Scenario:** Production-grade agent with persistence

**Specifications:**
- 1 agent pod: 0.5 CPU, 512Mi RAM
- Redis instance: 0.25 CPU, 256Mi RAM
- Postgres instance: 0.25 CPU, 512Mi RAM
- Minimal LLM usage: ~1000 calls/month

**Monthly Cost:**
```
Agent pod: 0.5 CPU Ã— 730 hrs Ã— $0.04/hr = $14.60
Redis: 0.25 CPU Ã— 730 hrs Ã— $0.04/hr = $7.30
Postgres: 0.25 CPU Ã— 730 hrs Ã— $0.04/hr = $7.30
LLM (GPT-4): 1000 calls Ã— $0.01 = $10.00

Subtotal: $39.20
With discounts/spot: ~$15-20/month
```

**Cost Optimization:**
- Use managed Redis/Postgres (cheaper at scale)
- Implement aggressive LLM caching
- Use cheaper models (GPT-3.5) for simple cases
- Batch investigations to reduce overhead

---

## ğŸ“ Key Learning Outcomes

### Conceptual Understanding

After completing this lab, you understand:

âœ… **Production Agent Architecture:**
- Multi-layer memory for different use cases
- Tool management with rich metadata
- Safe execution with sandboxing
- LLM integration with fallbacks

âœ… **Memory Systems:**
- Working memory for recent context (cache-like)
- Episodic memory for history (database-like)
- When to use each layer
- Memory integration patterns

âœ… **Tool Governance:**
- Permission systems
- Timeout enforcement
- Rate limiting
- Retry strategies

âœ… **LLM Integration:**
- Provider abstraction
- Prompt engineering
- Fallback strategies
- Cost optimization

### Technical Skills

You can now:

âœ… **Design multi-layer memory** for agents
âœ… **Implement tool registries** with metadata
âœ… **Build safe executors** with sandboxing
âœ… **Integrate LLMs** with fallbacks
âœ… **Deploy stateful agents** with persistence
âœ… **Test complex systems** systematically
âœ… **Debug production agents** effectively

### Real-World Patterns

You've learned:

âœ… **Enterprise agent architecture** - Production-ready design
âœ… **Memory layer separation** - Right storage for each use case
âœ… **Tool safety patterns** - Governance and control
âœ… **Graceful degradation** - Working without LLMs
âœ… **Historical learning** - Using past investigations

---

## ğŸ”§ Troubleshooting

### Issue: LLM Calls Failing

**Symptoms:**
- Plans seem generic
- No reasoning in responses

**Check LLM status:**
```bash
curl http://localhost:8000/health
```

Look for:
```json
{
  "llm_available": false,
  "using_fallback": true
}
```

**Solution:**
```bash
# Set API key
export OPENAI_API_KEY="sk-your-key"

# Install package
pip install openai

# Restart agent
```

### Issue: Memory Not Persisting

**Check database file:**
```bash
ls -la episodic.db
```

**Test memory directly:**
```bash
sqlite3 episodic.db "SELECT * FROM investigations;"
```

### Issue: Tools Timing Out

**Check tool metadata:**
```python
# Increase timeout in tools.py
"timeout_seconds": 60  # Increase from 30
```

**Check logs:**
```bash
kubectl logs -n ai-ml-lab-4-1-paid -l app=paid-agent
```

---

## ğŸ§¹ Cleanup

### Remove Kubernetes Resources

```bash
kubectl delete namespace ai-ml-lab-4-1-paid
```

### Delete kind Cluster

```bash
kind delete cluster --name mcp-cluster
```

### Clean Local Files

```bash
cd lab-04.1-first-ai-agent-paid/app
rm -f episodic.db  # SQLite database
rm -rf .venv
```

---

## ğŸ“š Next Steps

### Production Enhancements

**1. Real Database Integration:**
```python
# Replace SQLite with Postgres
from sqlalchemy import create_engine
engine = create_engine("postgresql://user:pass@host/db")
```

**2. Real Redis Integration:**
```python
import redis
working_memory = redis.Redis(host='localhost', port=6379)
```

**3. Advanced Tool Governance:**
- Implement approval workflows
- Add audit logging
- Create tool usage dashboards
- Set up cost tracking

**4. LLM Optimization:**
- Implement prompt caching
- Use function calling
- Add streaming responses
- Implement token budgets

**5. Observability:**
- Add OpenTelemetry tracing
- Track tool execution metrics
- Monitor memory usage
- Alert on failures

---

## ğŸ‰ Congratulations!

You've built a production-grade AI agent!

### What You've Mastered:

âœ… **Production Agent Architecture** - Enterprise-ready design  
âœ… **Multi-Layer Memory** - Working + Episodic memory systems  
âœ… **Tool Governance** - Metadata-driven execution  
âœ… **LLM Integration** - With intelligent fallbacks  
âœ… **Safe Execution** - Sandboxing and error handling  
âœ… **State Management** - Persistence and recovery  

### Real-World Impact:

These patterns power:
- **Autonomous incident response** at major tech companies
- **Self-healing infrastructure** systems
- **Intelligent DevOps assistants**
- **Enterprise automation platforms**

You now have production-grade agent development skills!

Happy learning! ğŸš€ğŸ¤–ğŸ”§ğŸ’¾